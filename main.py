import os
import requests
import json
import re
import xml.etree.ElementTree as ET
from datetime import datetime
from openai import OpenAI

# === 1. é…ç½®åŒºåŸŸ ===
# âš ï¸ è°ƒè¯•å¼€å…³ï¼šTrue = åªæ‰“å°ä¸å‘é€ï¼›False = æ­£å¼å‘é€
DRY_RUN = True 

WEBHOOK_URL = os.environ.get("WECOM_WEBHOOK_KEY")
DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")

# åˆå§‹åŒ– DeepSeek
client = OpenAI(
    api_key=DEEPSEEK_KEY,
    base_url="https://api.deepseek.com"
)

# === RSS æŠ“å–å™¨ ===
def fetch_rss_data(rss_url):
    # æ‰“å°ä¸€ä¸‹å½“å‰çš„ URLï¼Œç¡®ä¿å®ƒæ˜¯çº¯å‡€çš„
    print(f"ğŸ”„ æ­£åœ¨è¿æ¥ä¼˜è®¾ç½‘: {rss_url}")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    items = []
    try:
        response = requests.get(rss_url, headers=headers, timeout=15)
        if response.status_code == 200:
            try:
                root = ET.fromstring(response.content)
                nodes = root.findall('.//item')
                
                # è°ƒè¯•æ¨¡å¼ä¸‹åªå¤„ç†å‰ 3 æ¡
                limit = 3 if DRY_RUN else 15
                print(f"ğŸ§ª è°ƒè¯•æ¨¡å¼ï¼šå¤„ç†å‰ {limit} æ¡" if DRY_RUN else f"ğŸš€ æ­£å¼æ¨¡å¼ï¼šå¤„ç†å‰ {limit} æ¡")

                for item in nodes[:limit]: 
                    title = item.find('title').text if item.find('title') is not None else "æ— æ ‡é¢˜"
                    link = item.find('link').text if item.find('link') is not None else ""
                    
                    desc = ""
                    desc_node = item.find('description')
                    if desc_node is not None and desc_node.text:
                        desc = re.sub(r'<[^>]+>', '', desc_node.text)
                    
                    if link and title:
                        items.append({
                            "title": title,
                            "original_summary": desc[:500],
                            "url": link
                        })
                
                print(f"âœ… æˆåŠŸè·å– {len(items)} æ¡èµ„è®¯")
                return items
            except Exception as e:
                print(f"âŒ XML è§£æå¤±è´¥: {e}")
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
    except Exception as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯ (å¯èƒ½æ˜¯ URL æ ¼å¼ä¸å¯¹): {e}")
    
    return items

def process_news_with_ai(news_list):
    if not news_list: return []
        
    print(f"ğŸ§  AI æ­£åœ¨æç‚¼ {len(news_list)} æ¡èµ„è®¯çš„é‡ç‚¹...")
    
    # æ„é€  Prompt ç´ æ
    input_data = [{"title": n["title"], "summary": n["original_summary"], "url": n["url"]} for n in news_list]
    raw_text = json.dumps(input_data, ensure_ascii=False)
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ã€æç®€ä¸»ä¹‰èµ„è®¯ç¼–è¾‘ã€‘ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯é‡å†™æ–°é—»æ‘˜è¦ã€‚

    ã€å¤„ç†è¦æ±‚ã€‘ï¼š
    1. **æ ‡é¢˜**ï¼šä¼˜åŒ–æ ‡é¢˜ï¼Œä½¿å…¶æ›´å…·å¸å¼•åŠ›ã€‚
    2. **æ‘˜è¦**ï¼š
       - å®Œå…¨é‡å†™åŸæ–‡ã€‚
       - **æçŸ­**ï¼šä¸¥æ ¼æ§åˆ¶åœ¨ 30-50 å­—ä»¥å†…ã€‚
       - **ç›´å‡»é‡ç‚¹**ï¼šç›´æ¥è¯´æ ¸å¿ƒå¹²è´§ã€‚
       - **ä¸¥ç¦åºŸè¯**ï¼šä¸è¦å‡ºç°â€œæœ¬æ–‡ä»‹ç»äº†â€ã€â€œæ–‡ç« æåˆ°â€ç­‰å­—çœ¼ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    å¿…é¡»è¿”å› JSON å¯¹è±¡ï¼Œä¸”**å¿…é¡»ä¿ç•™åŸå§‹ URL**ï¼š
    {
        "news": [
            {
                "title": "æ–°æ ‡é¢˜",
                "summary": "æç®€æ‘˜è¦å†…å®¹",
                "url": "åŸå§‹URL(ç»å¯¹ä¸èƒ½æ”¹)"
            }
        ]
    }
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·å¤„ç†ï¼š{raw_text}"}
            ],
            response_format={ "type": "json_object" }, 
            temperature=0.3
        )
        content = response.choices[0].message.content
        if content.startswith("```"): content = re.sub(r"^```json\s*|\s*```$", "", content, flags=re.MULTILINE)
        result = json.loads(content)
        
        if isinstance(result, dict) and "news" in result:
            return result["news"]
            
        return []
        
    except Exception as e:
        print(f"âŒ AI å¤„ç†å¤±è´¥: {e}")
        return []

def send_wecom(news_list):
    if not news_list: return

    today = datetime.now().strftime("%mæœˆ%dæ—¥")
    content_lines = [f"### ğŸ¨ ä¼˜è®¾çµæ„Ÿæ—©æŠ¥ ({today})"]
    
    for idx, news in enumerate(news_list, 1):
        title = news.get('title', 'æ— æ ‡é¢˜')
        url = news.get('url', '#')
        summary = news.get('summary', 'æš‚æ— ä»‹ç»')
        
        content_lines.append(f"**{idx}. [{title}]({url})**")
        content_lines.append(f"> {summary}")
        content_lines.append("") 

    final_content = "\n".join(content_lines)

    # === æ‹¦æˆªé€»è¾‘ ===
    if DRY_RUN:
        print("\n" + "="*30)
        print("ğŸ“¢ [æ¨¡æ‹Ÿå‘é€] çœ‹èµ·æ¥ä¸é”™ï¼æ­£å¼å†…å®¹å¦‚ä¸‹ï¼š")
        print("="*30)
        print(final_content)
        print("="*30 + "\n")
        print("âœ… éªŒè¯é€šè¿‡ï¼æœªå‘é€åˆ°ä¼ä¸šå¾®ä¿¡ã€‚")
        return
    # ================

    if not WEBHOOK_URL: return
    
    data = {"msgtype": "markdown", "markdown": {"content": final_content}}
    
    try:
        requests.post(WEBHOOK_URL, json=data)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨é€å¤±è´¥: {e}")

if __name__ == "__main__":
    # ä¿®æ­£ç‚¹ï¼šè¿™é‡Œå¿…é¡»æ˜¯çº¯å‡€çš„å­—ç¬¦ä¸²ï¼Œä¸èƒ½æœ‰ [] æˆ– ()
    target_url = "[https://www.uisdc.com/news/feed](https://www.uisdc.com/news/feed)"
    
    raw_news = fetch_rss_data(target_url)
    
    if not raw_news:
        print("âŒ æŠ“å–å¤±è´¥")
    else:
        final_news = process_news_with_ai(raw_news)
        if final_news:
            send_wecom(final_news)
        else:
            print("âš ï¸ AI æœªç­›é€‰å‡ºç»“æœ")
