import os
import requests
import json
import re
from datetime import datetime
from openai import OpenAI
# å¼•å…¥æ–°æœ‹å‹ï¼šBeautifulSoup (ä¸“é—¨ç”¨æ¥è§£æç½‘é¡µ HTML)
from bs4 import BeautifulSoup 

# === 1. é…ç½®åŒºåŸŸ ===
# âš ï¸ è°ƒè¯•æ¨¡å¼ï¼šTrue = åªæ‰“å°ä¸å‘é€ï¼›False = æ­£å¼å‘é€
DRY_RUN = True 

WEBHOOK_URL = os.environ.get("WECOM_WEBHOOK_KEY")
DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")

client = OpenAI(
    api_key=DEEPSEEK_KEY,
    base_url="https://api.deepseek.com"
)

# === 2. ç½‘é¡µçˆ¬è™«æŠ“å–å™¨ (é’ˆå¯¹ HTML) ===
def fetch_uisdc_news_html():
    target_url = "https://www.uisdc.com/news"
    print(f"ğŸ”„ æ­£åœ¨åƒæµè§ˆå™¨ä¸€æ ·è®¿é—®: {target_url}")
    
    headers = {
        # å¿…é¡»ä¼ªè£…æˆæµè§ˆå™¨ï¼Œå¦åˆ™ä¼˜è®¾å¯èƒ½ä¼šæ‹¦æˆª
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.uisdc.com/",
        "Accept-Language": "zh-CN,zh;q=0.9"
    }
    
    items = []
    try:
        response = requests.get(target_url, headers=headers, timeout=15)
        response.encoding = 'utf-8' # å¼ºåˆ¶ä½¿ç”¨ utf-8 é˜²æ­¢ä¹±ç 
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # === ğŸ•µï¸â€â™‚ï¸ é¡µé¢ç»“æ„å®šä½ (æ ¸å¿ƒé€»è¾‘) ===
            # ä¼˜è®¾è¯»æŠ¥çš„ç»“æ„é€šå¸¸æ˜¯ .news-list ä¸‹çš„ .item æˆ–è€…ç›´æ¥æ˜¯ article æ ‡ç­¾
            # æˆ‘ä»¬å°è¯•æŸ¥æ‰¾é¡µé¢ä¸Šæ‰€æœ‰å¸¦æœ‰ "è¯»æŠ¥" ç‰¹å¾çš„åˆ—è¡¨ï¼Œæˆ–è€…ç›´æ¥æ‰¾æ–‡ç« æ ‡é¢˜
            
            # ç­–ç•¥1ï¼šæŸ¥æ‰¾ .news-item (æœ€å¸¸è§çš„è®¾è®¡ç±»ç½‘ç«™å‘½å)
            # ç­–ç•¥2ï¼šæŸ¥æ‰¾ h2 æˆ– h3 æ ‡ç­¾ä¸­åŒ…å«é“¾æ¥çš„
            
            # è¿™é‡Œä½¿ç”¨æ›´ç¨³å¥çš„æŸ¥æ‰¾ï¼šæ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸï¼Œç„¶åæå–æ ‡é¢˜
            # å‡è®¾ä¼˜è®¾çš„æ–°é—»æ ‡é¢˜åœ¨ h3 æˆ– h2 æ ‡ç­¾é‡Œ
            news_nodes = soup.find_all(['h3', 'h2'])
            
            count = 0
            for node in news_nodes:
                if count >= 8: break # è¿™é‡Œçš„â€œè¯»æŠ¥â€å¯èƒ½å¾ˆå¤šï¼Œæˆ‘ä»¬åªå–å‰8æ¡æœ€æ–°çš„
                
                link_tag = node.find('a')
                if not link_tag: continue
                
                title = link_tag.get_text(strip=True)
                href = link_tag.get('href')
                
                # è¿‡æ»¤æ‰æ— æ•ˆçš„ã€æˆ–è€…ä¸æ˜¯æ–°é—»çš„æ ‡é¢˜ (æ¯”å¦‚ä¾§è¾¹æ å¹¿å‘Š)
                if len(title) < 5: continue 
                
                # å°è¯•æŠ“å–ç´§è·Ÿåœ¨æ ‡é¢˜åé¢çš„æè¿° (é€šå¸¸æ˜¯ <p>)
                desc = ""
                parent = node.parent
                desc_node = parent.find('p')
                if desc_node:
                    desc = desc_node.get_text(strip=True)
                
                # ä¼˜è®¾çš„é“¾æ¥æœ‰æ—¶æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå¤„ç†ä¸€ä¸‹
                if href and not href.startswith('http'):
                    href = f"https://www.uisdc.com{href}"
                    
                if title and href:
                    items.append({
                        "title": title,
                        "original_summary": desc[:200], # æˆªå–å‰200å­—ç»™AI
                        "url": href
                    })
                    count += 1
            
            print(f"âœ… æˆåŠŸä»é¡µé¢è§£æå‡º {len(items)} æ¡æ–°é—»")
            return items
        else:
            print(f"âŒ é¡µé¢è¯·æ±‚å¤±è´¥: {response.status_code}")
    except Exception as e:
        print(f"âŒ çˆ¬è™«å‘ç”Ÿé”™è¯¯: {e}")
    
    return items

# === 3. AI å¤„ç†é€»è¾‘ ===
def process_news_with_ai(news_list):
    if not news_list: return []
    
    print(f"ğŸ§  AI æ­£åœ¨é˜…è¯»å¹¶æç‚¼ {len(news_list)} æ¡æ–°é—»...")
    
    input_data = [{"title": n["title"], "summary": n["original_summary"], "url": n["url"]} for n in news_list]
    raw_text = json.dumps(input_data, ensure_ascii=False)
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ã€æç®€èµ„è®¯ç¼–è¾‘ã€‘ã€‚ä½ çš„ä»»åŠ¡æ˜¯é‡å†™ä¼˜è®¾è¯»æŠ¥çš„æ‘˜è¦ã€‚
    
    ã€å¤„ç†è¦æ±‚ã€‘ï¼š
    1. **æ ‡é¢˜**ï¼šä¼˜åŒ–æ ‡é¢˜ï¼Œä½¿å…¶æ›´å¸å¼•è®¾è®¡å¸ˆã€‚
    2. **æ‘˜è¦**ï¼š
       - **å®Œå…¨é‡å†™**åŸæ–‡ã€‚
       - **æçŸ­**ï¼šæ§åˆ¶åœ¨ 30-40 å­—ä»¥å†…ã€‚
       - **ç›´å‡»é‡ç‚¹**ï¼šç›´æ¥è¯´è¿™ä¸ªå·¥å…·æˆ–æ–°é—»å¯¹è®¾è®¡å¸ˆæœ‰ä»€ä¹ˆç”¨ã€‚
       - **ä¿ç•™ URL**ï¼šå¿…é¡»åŸæ ·è¿”å› URLã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    {
        "news": [
            {
                "title": "æ–°æ ‡é¢˜",
                "summary": "æç®€æ‘˜è¦",
                "url": "åŸå§‹URL"
            }
        ]
    }
    """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·å¤„ç†ï¼š{raw_text}"}
            ],
            response_format={ "type": "json_object" }, 
            temperature=0.3
        )
        content = response.choices[0].message.content
        if content.startswith("```"): content = re.sub(r"^```json\s*|\s*```$", "", content, flags=re.MULTILINE)
        result = json.loads(content)
        
        if isinstance(result, dict):
            if "news" in result: return result["news"]
            for k, v in result.items():
                if isinstance(v, list): return v
        return []
    except Exception as e:
        print(f"âŒ AI å¤„ç†å¤±è´¥: {e}")
        return []

# === 4. æ¨é€é€»è¾‘ ===
def send_wecom(news_list):
    if not news_list: return

    today = datetime.now().strftime("%mæœˆ%dæ—¥")
    content_lines = [f"### ğŸ¨ ä¼˜è®¾çµæ„Ÿæ—©æŠ¥ ({today})"]
    
    for idx, news in enumerate(news_list, 1):
        title = news.get('title', 'æ— æ ‡é¢˜')
        url = news.get('url', '#')
        summary = news.get('summary', 'æš‚æ— ä»‹ç»')
        
        content_lines.append(f"**{idx}. [{title}]({url})**")
        content_lines.append(f"> {summary}")
        content_lines.append("") 

    final_content = "\n".join(content_lines)

    if DRY_RUN:
        print("\n" + "="*30)
        print("ğŸ“¢ [æ¨¡æ‹Ÿå‘é€] æœ€ç»ˆæ•ˆæœå¦‚ä¸‹ï¼š")
        print("="*30)
        print(final_content)
        print("="*30 + "\n")
        return

    if not WEBHOOK_URL: return
    data = {"msgtype": "markdown", "markdown": {"content": final_content}}
    try:
        requests.post(WEBHOOK_URL, json=data)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨é€å¤±è´¥: {e}")

if __name__ == "__main__":
    # 1. çˆ¬å– HTML
    raw_news = fetch_uisdc_news_html()
    
    if not raw_news:
        print("âŒ æ²¡æŠ“åˆ°ä»»ä½•æ–°é—»ï¼Œå¯èƒ½æ˜¯ä¼˜è®¾ç½‘æ”¹ç‰ˆäº† HTML ç»“æ„")
    else:
        # 2. AI æ¶¦è‰²
        final_news = process_news_with_ai(raw_news)
        if final_news:
            send_wecom(final_news)
        else:
            print("âš ï¸ AI æœªç­›é€‰å‡ºç»“æœ")
