import os
import requests
import json
import re
import time
from datetime import datetime
from openai import OpenAI
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# === 1. é…ç½®åŒºåŸŸ ===
# âš ï¸ è°ƒè¯•æ¨¡å¼ï¼šTrue = åªæ‰“å°ä¸å‘é€ï¼›False = æ­£å¼å‘é€
# éªŒè¯é€šè¿‡åï¼Œè®°å¾—æ”¹æˆ False
DRY_RUN = True

WEBHOOK_URL = os.environ.get("WECOM_WEBHOOK_KEY")
DEEPSEEK_KEY = os.environ.get("DEEPSEEK_API_KEY")

if DEEPSEEK_KEY:
    client = OpenAI(
        api_key=DEEPSEEK_KEY,
        base_url="https://api.deepseek.com"
    )
else:
    client = None
    print("âš ï¸ Warning: DEEPSEEK_API_KEY not set. AI processing will skipped or fail.")

# === 2. ç½‘é¡µçˆ¬è™« (Selenium Version) ===
def fetch_uisdc_news_html():
    target_url = "https://www.uisdc.com/news"
    
    # Configure Headless Chrome
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1920,1080")
    # Mimic a real user agent to avoid being blocked
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    driver = None
    try:
        print(f"ğŸ”„ Launching Browser for {target_url}...")
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get(target_url)
        
        # Wait for the Dubao items to load (dynamic content)
        # We wait up to 15 seconds for .dubao-item to appear
        try:
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "dubao-item"))
            )
            print("âœ… Dynamic content loaded.")
        except Exception:
            print("âš ï¸ Timeout waiting for .dubao-item. Page might have changed or loaded slowly.")

        # Get the page source after JS execution
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Target Dubao items
        news_items = soup.select('.dubao-item')
        
        if not news_items:
            print("âš ï¸ Still did not find .dubao-item after JS wait.")
            return []

        # User request: Limit to top 20 items
        news_items = news_items[:20]
        print(f"âœ… Found {len(news_items)} items. Processing...")

        valid_news = []
        
        for item in news_items:
            # Title: .dubao-title
            title_tag = item.select_one('.dubao-title')
            if title_tag:
                num_tag = title_tag.select_one('.num')
                if num_tag:
                    num_tag.decompose()
                title = title_tag.get_text(strip=True)
            else:
                title = ""
            
            # Content: .dubao-content
            content_tag = item.select_one('.dubao-content')
            summary = content_tag.get_text(strip=True) if content_tag else ""
            
            # --- FILTERING LOGIC ---
            # Strictly exclude "ä¼˜è®¾"
            if "ä¼˜è®¾" in title or "ä¼˜è®¾" in summary:
                print(f"ğŸš« Filtered (contains ä¼˜è®¾): {title}")
                continue
                
            # Basic validation
            if title:
                # User requested NO LINKS. We store only Title and Summary.
                # We do NOT scrape the URL anymore as it's not needed for output.
                valid_news.append({
                    "title": title,
                    "summary": summary
                })
            
        return valid_news

    except Exception as e:
        print(f"âŒ Browser/Scraping Error: {e}")
        return []
    finally:
        if driver:
            driver.quit()

# === 3. AI æ¶¦è‰² ===
def process_news_with_ai(news_list):
    if not news_list or not client:
        return news_list 
        
    formatted_input = ""
    for idx, item in enumerate(news_list):
        formatted_input += f"{idx+1}. Title: {item['title']} | Summary: {item['summary']}\n"

    print("ğŸ¤– Sending to AI for polishing...")
    
    try:
        completion = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹èšåˆç¼–è¾‘ã€‚è¯·åˆ†æè¾“å…¥çš„æ–°é—»åˆ—è¡¨ï¼Œåªä¿ç•™è·Ÿ AIã€äº§å“ã€è®¾è®¡è¶‹åŠ¿å¼ºç›¸å…³çš„å†…å®¹ã€‚è¯·è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼ŒåŒ…å«å­—æ®µ 'news'ï¼Œå€¼æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ åŒ…å« 'title' (åŸæ ‡é¢˜) å’Œ 'summary' (åŸºäºå†…å®¹ç”Ÿæˆçš„å¸å¼•äººçš„ç®€çŸ­æ¨èè¯­ï¼Œ50å­—ä»¥å†…)ã€‚âš ï¸ é‡è¦ï¼šç»å¯¹ä¸è¦åŒ…å«ä»»ä½•å¸¦æœ‰ 'ä¼˜è®¾' å­—æ ·çš„å†…å®¹ã€‚ç”±äºç”¨æˆ·è¦æ±‚ä¸åŒ…å«é“¾æ¥ï¼Œè¯·ä¸è¦è¿”å› url å­—æ®µã€‚"
                },
                {
                    "role": "user",
                    "content": f"è¯·å¤„ç†ä»¥ä¸‹æ–°é—»åˆ—è¡¨:\n{formatted_input}"
                }
            ],
            max_tokens=2048,
            temperature=0.7,
            stream=False,
            response_format={"type": "json_object"}
        )
        
        result_content = completion.choices[0].message.content
        result = json.loads(result_content)
        
        final_list = []
        if isinstance(result, dict) and 'news' in result and isinstance(result['news'], list):
            for item in result['news']:
                t = item.get('title', '')
                s = item.get('summary', '')
                if "ä¼˜è®¾" not in t and "ä¼˜è®¾" not in s:
                    final_list.append(item)
                    
        return final_list

    except Exception as e:
        print(f"âŒ AI å¤„ç†å¤±è´¥: {e}")
        return news_list

# === 4. æ¨é€é€»è¾‘ (NO LINKS) ===
def send_wecom(news_list):
    if not news_list:
        print("ğŸ“­ æ— å†…å®¹å¯å‘é€")
        return

    today = datetime.now().strftime("%mæœˆ%dæ—¥")
    content_lines = [f"### ğŸš€ AI & Design News ({today})"] 
    
    for idx, news in enumerate(news_list, 1):
        title = news.get('title', 'æ— æ ‡é¢˜')
        summary = news.get('summary', '')
        
        # User requested: "æŠŠé“¾æ¥è¿‡æ»¤æ‰ï¼Œå¾®ä¿¡çœ‹ä¸åˆ°ä»»ä½•å›¾ç‰‡é“¾æ¥"
        # Output format: **1. Title** \n > Summary
        content_lines.append(f"**{idx}. {title}**")
        if summary:
            content_lines.append(f"> {summary}")
        content_lines.append("") 

    final_content = "\n".join(content_lines)

    if DRY_RUN:
        print("\n" + "="*30)
        print("ğŸ“¢ [æ¨¡æ‹Ÿå‘é€] æœ€ç»ˆæ•ˆæœå¦‚ä¸‹ï¼š")
        print("="*30)
        print(final_content)
        print("="*30 + "\n")
        return

    if not WEBHOOK_URL:
        print("âš ï¸ No Webhook URL set")
        return
        
    data = {"msgtype": "markdown", "markdown": {"content": final_content}}
    try:
        requests.post(WEBHOOK_URL, json=data)
        print("âœ… æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨é€å¤±è´¥: {e}")

if __name__ == "__main__":
    # 1. çˆ¬å– (Selenium)
    raw_news = fetch_uisdc_news_html()
    
    if not raw_news:
        print("âŒ æ²¡æŠ“åˆ°ä»»ä½•æ–°é—» (or all filtered)")
    else:
        # 2. AI æ¶¦è‰²
        final_news = process_news_with_ai(raw_news)
        
        # 3. å‘é€
        if final_news:
            # User request: Final push should only be 5 items
            final_news = final_news[:5]
            send_wecom(final_news)
        else:
            print("âš ï¸ æœ€ç»ˆåˆ—è¡¨ä¸ºç©º")
